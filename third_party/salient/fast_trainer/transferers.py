from MorphGL.utils import get_logger
mlog = get_logger()


import dgl
from typing import List
#from collections.abc import Iterator
from typing import Iterator
import torch

from .samplers import ProtoBatch, PreparedBatch
from .utils import append_runtime_stats, Timer, runtime_stats_cuda
import time

from torch.profiler import profile, record_function, ProfilerActivity

class FixedStepPrefetcher(Iterator):
    """
    fixed behavior pattern for dataloader:
    repeat the following two phase until end:
    * first K-1 batches are generated by UVA, then the K-th batch is UVA+preload
    * next N-1 batches are sync+preload, then the N+K-th batch is sync

    in other words, we have four kind of behaviors when entering the __next__ method
    1. UV: generate a batch with UVA
    2. UVPR: generate a batch with UVA, and (blockingly) preload a CPU batch
    3. SYNC: sync and return a CPU batch
    4. SYPR: and return a CPU batch, and (blockingly) preload a CPU batch

    """

    def __init__(self, device, cpu_it: Iterator[PreparedBatch], gpu_it, K, N):
        self.device = device
        self.cpu_it = cpu_it
        self.gpu_it = gpu_it
        self.K = K
        self.N = N
        assert self.K + self.N > 0
        self.copy_stream = torch.cuda.Stream(self.device)

        self.flag_cpu_end = False
        self.flag_gpu_end = self.gpu_it.length == 0
        self.next_batch = None
        self.behaviors = self.behavior_generator()
        mlog(f"gpu length: {self.gpu_it.length}, cpu length: {self.cpu_it.length}")

    def preload(self):
        self.next_batch = None
        if self.flag_cpu_end:
            return
        batch = next(self.cpu_it)
        if batch is None:
            self.flag_cpu_end = True
            return
        with torch.cuda.stream(self.copy_stream):
            self.next_batch = batch.to(self.device, non_blocking=True)
        #self.flag_cpu_end = self.cpu_it.generated_batch == self.cpu_it.length

    def behavior_generator(self):
        while True:
            if self.K == 0: 
                # only CPU
                yield 'SYPR'
            elif self.N == 0:
                # only UVA
                yield 'UV'
            else:
                # mixed
                for _ in range(self.K-1):
                    yield 'UV'
                yield 'UVPR'
                for _ in range(self.N-1):
                    yield 'SYPR'
                yield 'SYNC'

    def __next__(self):
        if self.flag_gpu_end and self.flag_cpu_end:
            #torch.cuda.synchronize()
            #next(self.cpu_it)  # need to call again to make sure threads are released
            raise StopIteration

        cur_stream = torch.cuda.current_stream(self.device)
        cur_behavior = next(self.behaviors)

        if self.flag_gpu_end:
            # pure CPU, repeat SYPR until end
            if self.next_batch is None:
                self.preload()
            cur_behavior = 'SYPR'
        elif self.flag_cpu_end:
            # pure UVA, repeat UV until end
            cur_behavior = 'UV'
        else:
            # normal case, execute the current behavior
            pass

        if cur_behavior == 'UV':
            with record_function("UV"):
                batch = next(self.gpu_it)
                #mlog(f'UV, {self.gpu_it.idx}')
                self.flag_gpu_end = self.gpu_it.idx == self.gpu_it.length
                return batch
        elif cur_behavior == 'UVPR':
            with record_function("UVPR"):
                batch = next(self.gpu_it)
                #mlog(f'UVPR, {self.gpu_it.idx}')
                self.flag_gpu_end = self.gpu_it.idx == self.gpu_it.length
                self.copy_stream.wait_stream(cur_stream) # avoid async transfer contends pcie with uva
                self.preload()
                return batch
        elif cur_behavior  == 'SYNC':
            with record_function("SYNC"):
                cur_stream.wait_stream(self.copy_stream)
                ret = self.next_batch
                #mlog(f'SYNC, {self.cpu_it.generated_batch}')
                ret = convert_salient_to_dgl(ret)
                record_batch(ret, cur_stream)
                self.next_batch = None
                return ret
        elif cur_behavior == 'SYPR':
            with record_function("SYPR"):
                cur_stream.wait_stream(self.copy_stream)
                ret = self.next_batch
                #mlog(f'SYPR, {self.cpu_it.generated_batch}')
                ret = convert_salient_to_dgl(ret)
                record_batch(ret, cur_stream)
                self.preload()
                return ret
        else:
            # unrecognized behavior
            raise ValueError
        

class CSAPPPrefetcher(Iterator):

    def __init__(self, device, cpu_it: Iterator[PreparedBatch], gpu_it):
        self.device = device
        self.cpu_it = cpu_it
        self.gpu_it = gpu_it
        self.copy_stream = torch.cuda.Stream(self.device)

        self.flag_cpu_end = False
        self.flag_gpu_end = self.gpu_it.length == 0

        self.next_batch = None
        mlog(f"gpu length: {self.gpu_it.length}, cpu length: {self.cpu_it.length}")
        self.preload()

    def preload(self, cpu_blocking=False):
        self.next_batch = None
        if self.flag_cpu_end:
            return
        try:
            if cpu_blocking:
                batch = next(self.cpu_it)
            else:
                batch = self.cpu_it.try_one()
            if batch is not None:
                with torch.cuda.stream(self.copy_stream):
                    self.next_batch = batch.to(self.device, non_blocking=True)
                """
                # if convert2dgl on CPU before transfer
                x, y, adjs = convert_salient_to_dgl(batch)
                with torch.cuda.stream(self.copy_stream):
                    self.next_batch = (
                            x.to(self.device, non_blocking=True),
                            y.to(self.device, non_blocking=True),
                            [adj.to(self.device, non_blocking=True) for adj in adjs]
                            )
                """
        except StopIteration:
            self.flag_cpu_end = True
        except Exception as e:
            print(e)
            raise e

    def __next__(self):
        if self.flag_gpu_end and self.flag_cpu_end:
            #torch.cuda.synchronize()
            raise StopIteration

        cur_stream = torch.cuda.current_stream(self.device)

        # CPU batch ready, use it for training
        if not self.flag_gpu_end and self.next_batch and self.copy_stream.query():
            ret = self.next_batch
            mlog(f'1cpu batch, {self.cpu_it.generated_batch}')
            ret = convert_salient_to_dgl(ret)
            record_batch(ret, cur_stream)
            self.preload()
            return ret

        # either next_batch is None or transfer not finished, we first try GPU batching
        if not self.flag_gpu_end:
            batch = next(self.gpu_it)
            mlog(f'1gpu batch, {self.gpu_it.idx}')
            self.flag_gpu_end = self.gpu_it.idx == self.gpu_it.length
            if self.next_batch is None:
                self.preload()
            return batch

        # if GPU end, must be pure CPU batching phase
        if not self.flag_cpu_end:
            if self.next_batch is None:
                self.preload(cpu_blocking=True)
            cur_stream.wait_stream(self.copy_stream)
            ret = self.next_batch
            mlog(f'2cpu batch, {self.cpu_it.generated_batch}')
            ret = convert_salient_to_dgl(ret)
            record_batch(ret, cur_stream)
            self.preload(cpu_blocking=True)
            return ret

def convert_salient_to_dgl(salient_batch):
    with record_function("convert"):
        x = salient_batch.x
        y = salient_batch.y
        dgl_adjs = []
        for pyg_adj in salient_batch.adjs:
            adj_t = pyg_adj.adj_t
            size = pyg_adj.size
            #eid = pyg_adj.e_id
            rowptr, col, _ = adj_t.csr()
            dgl_adj = dgl.create_block(('csc', (rowptr, col, torch.Tensor())), num_dst_nodes=size[1], num_src_nodes=size[0])
            #dgl_adj.pin_memory_() # should pin if convert is done on CPU
            dgl_adjs.append(dgl_adj)
        return (x, y, dgl_adjs)

def record_batch(converted_batch, stream):
    with record_function("record_batch"):
        #x, y, adjs = converted_batch
        converted_batch[0].record_stream(stream) # x
        converted_batch[1].record_stream(stream) # y
        for adj in converted_batch[2]: # adjs
            adj.record_stream(stream)


class DeviceIterator(Iterator[List[PreparedBatch]]):
    '''
    Abstract class that returns PreparedBatch on devices (GPUs)
    '''
    devices: List[torch.cuda.device]

    def __init__(self, devices):
        assert len(devices) > 0
        self.devices = devices



class DevicePrefetcher(DeviceIterator):
    def __init__(self, devices, it: Iterator[PreparedBatch]):
        super().__init__(devices)

        self.it = it
        self.streams = [torch.cuda.Stream(device) for device in devices]
        self.next = []
        self.sampling_times = []
        self.record_stream_times = []
        self.start_prefetch_times = []
        self.wait_stream_times = []
        self.preload(False)

    def preload(self, timing=True):
        self.next = []
        for device, stream in zip(self.devices, self.streams):
            timer_start = time.perf_counter_ns()
            batch = next(self.it, None)
            timer_end = time.perf_counter_ns()
            if batch is None:
                append_runtime_stats("total:load_batch:sampling", sum(
                    self.sampling_times)/1000000)
                self.sampling_times = []
                append_runtime_stats("total:load_batch:data_transfer:start_nonblocking_prefetch", sum(
                    self.start_prefetch_times)/1000000)
                self.start_prefetch_times = []
                break

            timer_start = time.perf_counter_ns()
            with torch.cuda.stream(stream):
                self.next.append(batch.to(device, non_blocking=True))
            timer_end = time.perf_counter_ns()
            self.start_prefetch_times.append(timer_end-timer_start)

    def __next__(self):
        runtime_stats_cuda.start_region(
            "data_transfer", runtime_stats_cuda.get_last_event())

        timer_start = time.perf_counter_ns()
        cur_streams = [torch.cuda.current_stream(
            device) for device in self.devices]

        for cur_stream, stream in zip(cur_streams, self.streams):
            cur_stream.wait_stream(stream)
        runtime_stats_cuda.end_region("data_transfer")

        runtime_stats_cuda.start_region(
            "sampling", runtime_stats_cuda.get_last_event())

        ret = self.next
        timer_end = time.perf_counter_ns()
        self.wait_stream_times.append(timer_end-timer_start)
        if not ret:
            torch.cuda.synchronize()
            append_runtime_stats("total:load_batch:data_transfer:wait_stream", sum(
                self.wait_stream_times)/1000000)
            self.wait_stream_times = []
            append_runtime_stats("total:load_batch:data_transfer:record_stream", sum(
                self.record_stream_times)/1000000)
            self.record_stream_times = []
            raise StopIteration

        # TODO: this might be a bit incorrect
        # https://pytorch.org/docs/stable/generated/torch.Tensor.record_stream.html
        #
        # in theory, we want to record this event after all the
        # training computation on the default stream

        timer_start = time.perf_counter_ns()
        for cur_stream, batch in zip(cur_streams, ret):
            batch.record_stream(cur_stream)
        timer_stop = time.perf_counter_ns()
        self.record_stream_times.append(timer_stop-timer_start)

        self.preload()
        return ret


class DeviceTransferer(DeviceIterator):
    def __init__(self, devices, it: Iterator[PreparedBatch]):
        super().__init__(devices)

        self.it = it

    def __next__(self):
        ret = [batch.to(device, non_blocking=True)
               for device, batch in zip(self.devices, self.it)]
        if len(ret) == 0:
            raise StopIteration

        return ret


class DeviceSlicerTransferer(DeviceIterator):
    # NOTE: This class only exists to provide functionality
    #       that we used to have and no longer need (DATA_ON_MAIN).
    #       You likely do not need to use this.
    # NOTE: x and y can be GPU tensors too!
    def __init__(self, devices, x: torch.Tensor, y: torch.Tensor,
                 it: Iterator[ProtoBatch]):
        super().__init__(devices)

        self.x = x
        self.y = y
        self.it = it

    def __next__(self):
        ret = [PreparedBatch.from_proto_batch(
            self.x, self.y, proto_batch).to(device, non_blocking=True)
            for device, proto_batch in zip(self.devices, self.it)]

        if len(ret) == 0:
            raise StopIteration

        return ret
